{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bf4d163",
   "metadata": {},
   "source": [
    "# Dictionaries and sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba23ba7",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "_Python is basically dicts wrapped in loads of syntactic sugar._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a67211",
   "metadata": {},
   "source": [
    "We use dictionaries in all our programs, even if they are not explicitly defined, since they are a fundamental part of Python's implementation.\n",
    "\n",
    "Class, namespaces and all the keyword arguments are some of the core Python constructs, represented by dictionaries in memory.\n",
    "\n",
    "`__builtins__.__dict__` stores all built-in types, objects and functions.\n",
    "\n",
    "Because of their core role, `dict` objects are highly optimized, they are built on top of _hash tables_ helping in their performance.\n",
    "\n",
    "Other builtin Python types which rely on _hash tables_ are `set` and it's variation `frozenset`, this is a particular Python type used to implement all the funcamental set arithmetic, with them, we can express algorithms in a more pythonic way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10645c0",
   "metadata": {},
   "source": [
    "### Dict comprehensions\n",
    "\n",
    "Since Python 2.7, the syntax used for _genexps_ and _listcomps_ has been used for _dict comprehensions_, syntax that you'll find very familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18141d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{55: 'CDMX', 33: 'GDL', 81: 'MTY'}\n"
     ]
    }
   ],
   "source": [
    "codes = [\n",
    "    (55, \"CDMX\"),\n",
    "    (33, \"GDL\"),\n",
    "    (81, \"MTY\"),\n",
    "]\n",
    "\n",
    "dial = {country: code for country, code in codes}\n",
    "print(dial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f13a51",
   "metadata": {},
   "source": [
    "Please note that, in this particular case, the input for our dial dict comprehension is actually a list of tuples, the _dictcomp_ expression uses curly braces `{}` and expects to use `key: value` as the first element, after that you can use the typical `for` syntax used in _listcomps_ and _genexps_.\n",
    "\n",
    "As I said, this particular case uses a \"double input\" but you can always use a simple input of only one iterator variable, it all depends on the implementation you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7d27570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'stuff': 5, 'gain': 4, 'harmony': 7, 'integrity': 9, 'shoulder': 8, 'blind': 5, 'rugby': 5, 'marriage': 8, 'treat': 5, 'month': 5}\n"
     ]
    }
   ],
   "source": [
    "words = [\n",
    "    \"stuff\",\n",
    "    \"gain\",\n",
    "    \"harmony\",\n",
    "    \"integrity\",\n",
    "    \"shoulder\",\n",
    "    \"blind\",\n",
    "    \"rugby\",\n",
    "    \"marriage\",\n",
    "    \"treat\",\n",
    "    \"month\",\n",
    "]\n",
    "letter_count = {word: len(word) for word in words}\n",
    "print(letter_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af64776",
   "metadata": {},
   "source": [
    "In the example above, I generated a new dict of a string key using the words from the list, and with a value using the length of it, only with one iterator variable.\n",
    "\n",
    "Although, dictionaries are not quite sortable, it does not meant you can't sort them, but we'll see further an specific varaition of this type named `OrderedDict` used in this cases, by the meantime you can sort using a pipeline of `items`, `sorted` and `dict` functions, using `sorted` you are able to specify the ordering method with the `key` callable argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "610ee677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blind': 5,\n",
       " 'gain': 4,\n",
       " 'harmony': 7,\n",
       " 'integrity': 9,\n",
       " 'marriage': 8,\n",
       " 'month': 5,\n",
       " 'rugby': 5,\n",
       " 'shoulder': 8,\n",
       " 'stuff': 5,\n",
       " 'treat': 5}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Order alphabetically\n",
    "dict(sorted(letter_count.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7b7b104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gain': 4,\n",
       " 'stuff': 5,\n",
       " 'blind': 5,\n",
       " 'rugby': 5,\n",
       " 'treat': 5,\n",
       " 'month': 5,\n",
       " 'harmony': 7,\n",
       " 'shoulder': 8,\n",
       " 'marriage': 8,\n",
       " 'integrity': 9}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Order by length\n",
    "dict(sorted(letter_count.items(), key=lambda k: k[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6cf07e",
   "metadata": {},
   "source": [
    "### Unpacking dicts\n",
    "\n",
    "Dictionaries are unpackable as tuples and sequences, the first way to unpack a dictionary is using the `**` operator, this works when keys are all strings and unique across all arguments, sicne duplicated arguments are forbidden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e65e214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3}\n",
      "{'name': 'John', 'lastname': 'Doe'}\n"
     ]
    }
   ],
   "source": [
    "def dump(**kwargs):\n",
    "    return kwargs\n",
    "\n",
    "print(dump(a=1, b=2, c=3))\n",
    "print(dump(name=\"John\", lastname=\"Doe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e558775c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 1, 'y': 2, 'z': 3}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can actually use the ** operator to unpack in unpackings\n",
    "dump(**{\"x\": 1}, y=2, **{\"z\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d167248",
   "metadata": {},
   "source": [
    "### Merging dicts\n",
    "\n",
    "Since Python 3.9, the operator `|` and `|=` is available to merge dicts, this operator does not affect any of the inputs, instead, it creates a new `dict` object with the merged values of all the inputs, please note that the interpreter will always take the last value for repeated keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcfb39d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John',\n",
       " 'lastname': 'Doe',\n",
       " 'age': 25,\n",
       " 'role': 'Python Dev',\n",
       " 'seniority': 'Senior'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person = {\"name\": \"John\", \"lastname\": \"Doe\", \"age\": 25}\n",
    "occupation = {\"role\": \"Python Dev\", \"seniority\": \"Senior\"}\n",
    "\n",
    "person | occupation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94c34d0",
   "metadata": {},
   "source": [
    "If a key is repeated, the interpreter will store the last occurrency of the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37b1c897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John',\n",
       " 'lastname': 'Doe',\n",
       " 'age': 25,\n",
       " 'role': 'Artist',\n",
       " 'seniority': 'Senior'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_job = {\"role\": \"Artist\"}\n",
    "\n",
    "person | occupation | desired_job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c4f07",
   "metadata": {},
   "source": [
    "### Pattern matching\n",
    "\n",
    "The `match/case` statement supports subjects that are mapping objects, patterns for mappings look like `dict` instances but they can match insances of any actual or virtual sublcass of `collections.abc.Mapping`.\n",
    "\n",
    "Thanks to destructurung, pattern matching is a powerful tool to process records structured as JSON and semi-destructured schemas like MongoDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5244e079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1  ['John Doe', 'Jane Doe']\n",
      "Case 2  ['Jane Doe']\n",
      "Case 3  ['John Doe']\n"
     ]
    }
   ],
   "source": [
    "def get_creators(record: dict) -> list:\n",
    "    match record:\n",
    "        case {\"type\": \"book\", \"api\": 2, \"authors\": [*names]}:\n",
    "            return names\n",
    "        case {\"type\": \"book\", \"api\": 1, \"author\": name}:\n",
    "            return [name]\n",
    "        case {\"type\": \"book\"}:\n",
    "            raise ValueError(f\"Invalid record {record!r}\")\n",
    "        case {\"type\": \"movie\", \"director\": name}:\n",
    "            return [name]\n",
    "        case _:\n",
    "            raise ValueError(f\"Invalid record {record!r}\")\n",
    "\n",
    "case_1 = {\"type\": \"book\", \"api\": 2, \"authors\": [\"John Doe\", \"Jane Doe\"]}\n",
    "print(\"Case 1 \", get_creators(case_1))\n",
    "\n",
    "case_2 = {\"type\": \"book\", \"api\": 1, \"author\": \"Jane Doe\"}\n",
    "print(\"Case 2 \", get_creators(case_2))\n",
    "\n",
    "case_3 = {\"type\": \"movie\", \"director\": \"John Doe\"}\n",
    "print(\"Case 3 \", get_creators(case_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87003a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case with ordered dict ['Bradbury', 'Gaiman']\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "case_ord = OrderedDict(type=\"book\", api=2, authors=[\"Bradbury\", \"Gaiman\"])\n",
    "\n",
    "print(\"Case with ordered dict\", get_creators(case_ord))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b62e994",
   "metadata": {},
   "source": [
    "In the last example above, note that the order of the keys is still irrelevant, even when the `Mapping` object actually cares about the order.\n",
    "\n",
    "Let's create a more complete example, sometimes, the `Mapping` objects may arrive with many more keys, although pattern will match, if you need to handle all of those extra key-value pars as a dict, you can use `**extra`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac4a561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'apocalypse now', 'duration': '2h33m'}\n",
      "['Francis Ford Coppola']\n"
     ]
    }
   ],
   "source": [
    "def get_creators(record: dict) -> list:\n",
    "    match record:\n",
    "        case {\"type\": \"book\", \"api\": 2, \"authors\": [*names], **extra}:\n",
    "            print(extra)\n",
    "            return names\n",
    "        case {\"type\": \"book\", \"api\": 1, \"author\": name, **extra}:\n",
    "            print(**extra)\n",
    "            return [name]\n",
    "        case {\"type\": \"book\"}:\n",
    "            raise ValueError(f\"Invalid record {record!r}\")\n",
    "        case {\"type\": \"movie\", \"director\": name, **extra}:\n",
    "            print(extra)\n",
    "            return [name]\n",
    "        case _:\n",
    "            raise ValueError(f\"Invalid record {record!r}\")\n",
    "            \n",
    "case_extra = dict(type=\"movie\", director=\"Francis Ford Coppola\", title=\"apocalypse now\", duration=\"2h33m\")\n",
    "print(get_creators(case_extra))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eab0608",
   "metadata": {},
   "source": [
    "### Standard API of mapping types\n",
    "\n",
    "As usual, `collections.abc` module provides the `Mapping` and  `MutableMApping` ABCs describing the interfaces of dict and similar types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1d0c312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import abc\n",
    "\n",
    "my_dict = dict()\n",
    "isinstance(my_dict, abc.Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3538fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(my_dict, abc.MutableMapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72119aed",
   "metadata": {},
   "source": [
    "To implement a custom mapping, the best idea might be to extend `collections.UserDict`, or to wrap `dict` by compositio rather than subclassing the ABCs. Since they are all based on a hash table functionality, the main limitation is that *all keys must be hashable* therefore *inmutable*.\n",
    "\n",
    "What is hashable?\n",
    "*According to the Python Glossary, an object is hashable is it has a hash code that never changes during its lifetime (it needs a `__hash__()` method), and can be compared to other objects (it needs an `__eq__()` method). Hashable objects which compare equal must have the same hash code.*\n",
    "\n",
    "Numeric and flat inmutable types `str` and `bytes` are all hashable, Container types are hashable if they are inmutables, and all their items are hashable as well.\n",
    "\n",
    "User defined types are hashable by default, because their hash code is calculated from their `id()` and the `__eq__()` method is inherited from the `object` class that compares their object IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffa444d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_1 id:  4424263392\n",
      "user_2 id:  4421431600\n",
      "user_1 hash:  276516462\n",
      "user_2 hash:  276339475\n"
     ]
    }
   ],
   "source": [
    "class User:\n",
    "    \n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "user_1 = User(\"Aldo\", 25)\n",
    "user_2 = User(\"Santiago\", 19)\n",
    "\n",
    "print(\"user_1 id: \", id(user_1))\n",
    "print(\"user_2 id: \", id(user_2))\n",
    "\n",
    "print(\"user_1 hash: \", hash(user_1))\n",
    "print(\"user_2 hash: \", hash(user_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63b670",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
